{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29b57150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T02:46:04.690085Z",
     "start_time": "2021-12-23T02:46:03.300528Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import warnings\n",
    "import json\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "from train_tools import EarlyStopping,get_logger\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score,recall_score\n",
    "from transformers import BertTokenizer,Adafactor,MT5ForConditionalGeneration\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from data_prepare import data_prepare,process_answer\n",
    "from dataset_and_model import JecT5Dataset,JecT5Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea1500b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T02:46:05.656808Z",
     "start_time": "2021-12-23T02:46:05.648554Z"
    }
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\", encoding=\"utf-8\")\n",
    "section_name = 't5'\n",
    "\n",
    "batch_size = config.getint(section_name,'batch_size')\n",
    "epochs = config.getint(section_name,'epochs')\n",
    "device = torch.device('cuda:'+config.get(section_name,'gpu') if torch.cuda.is_available else 'cpu')\n",
    "lr = config.getfloat(section_name,'batch_size')\n",
    "accum_step = config.getint(section_name,'accum_step')\n",
    "patience = config.getint(section_name,'patience')\n",
    "model_name = config.get(section_name,'model_name')\n",
    "model_savepath = config.get(section_name,'model_savepath')\n",
    "predict_savepath = config.get(section_name,'predict_savepath')\n",
    "log_path = config.get(section_name,'log_path')\n",
    "evaluate_path = config.get(section_name,'evaluate_path')\n",
    "\n",
    "train_datapath = config.get('DEFAULT','train_datapath')\n",
    "valid_datapath = config.get('DEFAULT','valid_datapath')\n",
    "test_datapath = config.get('DEFAULT','test_datapath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18789222",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T02:46:08.677165Z",
     "start_time": "2021-12-23T02:46:08.404456Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data,valid_data,test_data = data_prepare(train_datapath,test_datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fb2b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2c31eab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T02:46:12.354788Z",
     "start_time": "2021-12-23T02:46:12.325613Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0792185",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T08:17:54.147225Z",
     "start_time": "2021-12-21T08:17:53.778996Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.68it/s]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  7.27it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = JecT5Dataset(train_data,tokenizer)\n",
    "valid_data = JecT5Dataset(valid_data,tokenizer)\n",
    "train_loader = DataLoader(dataset=train_data,batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8456466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T02:46:25.602560Z",
     "start_time": "2021-12-23T02:46:14.085659Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net = JecT5Model(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81869314",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T08:18:07.881550Z",
     "start_time": "2021-12-21T08:18:07.878445Z"
    }
   },
   "outputs": [],
   "source": [
    "# tar = []\n",
    "# ans = []\n",
    "# net = net.to(device)\n",
    "# for batch in train_loader:\n",
    "#     target = batch['answer'].long().tolist()\n",
    "# #     inputs = {key:value.to(device) for key,value in batch.items() if key!='answer' and key!='id' and key!='labels'}\n",
    "# #     out = net.generate(inputs)\n",
    "# #     for i in out:\n",
    "# #         a = tokenizer.decode(i, skip_special_tokens=True)\n",
    "# #         res = pre_answer(a)\n",
    "# #         ans.append(res)\n",
    "#     tar.append(target)\n",
    "#     print(target)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10d4dc6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T02:48:15.979038Z",
     "start_time": "2021-12-23T02:48:15.959961Z"
    }
   },
   "outputs": [],
   "source": [
    "# def pre_answer(data):\n",
    "#     res = []\n",
    "#     res.append(1) if 'A' in data else res.append(0)\n",
    "#     res.append(1) if 'B' in data else res.append(0)\n",
    "#     res.append(1) if 'C' in data else res.append(0)\n",
    "#     res.append(1) if 'D' in data else res.append(0)\n",
    "#     return res\n",
    "def process_t5_answer(token):\n",
    "    if '对' in token:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 \n",
    "\n",
    "def get_metric(target,pred):\n",
    "    acc = accuracy_score(target,pred)\n",
    "    f1 = f1_score(target,pred,average='macro')\n",
    "    precision = precision_score(target,pred,average='macro')\n",
    "    recall = recall_score(target,pred,average='macro')\n",
    "    return acc,f1,precision,recall\n",
    "\n",
    "def train_per_epoch(train_loader,device,model,loss,opt,accum_step,log_per_step=None):\n",
    "    l_sum = 0\n",
    "    for i,batch in enumerate(tqdm(train_loader)):\n",
    "        inputs = {key:value.to(device) for key,value in batch.items() if key!='answer' and key!='id'}\n",
    "        l = model(inputs)\n",
    "        l_sum += l.item()\n",
    "        l = l/accum_step\n",
    "        l.backward()\n",
    "        if (i+1)%accum_step==0 or (i+1)==len(train_loader):\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "    return l_sum/len(train_loader)\n",
    "\n",
    "def evaluate_per_epoch(valid_loader,device,model,loss,epoch):\n",
    "    predicts = []\n",
    "    targets = []\n",
    "    contents = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader):\n",
    "            target = []\n",
    "            target_ = batch['answer'].long().tolist()\n",
    "            for i in range(0,batch_size,4):\n",
    "                target.append(target_[i])\n",
    "            inputs = {key:value.to(device) for key,value in batch.items() if key!='answer' and key!='id' and key!='labels'}\n",
    "            out = model.generate(inputs)\n",
    "            for i in out:\n",
    "                a = tokenizer.decode(i, skip_special_tokens=True)\n",
    "                contents.append(a)\n",
    "                predict = process_t5_answer(a)\n",
    "                predicts.append(predict)\n",
    "            targets.extend(target)\n",
    "            \n",
    "        final_out = torch.tensor(predicts,dtype=torch.long).reshape(-1,4).tolist()\n",
    "        valid_acc ,valid_f1 ,valid_precision ,valid_recall = get_metric(targets,final_out)\n",
    "    \n",
    "    with open(evaluate_path,'a') as f:\n",
    "        f.write('epoch:'+str(epoch)+'\\n')\n",
    "        for i in contents[:100]:\n",
    "            f.write(str(i)+'\\n')\n",
    "    return valid_acc,valid_precision,valid_recall,valid_f1\n",
    "    \n",
    "def train(train_loader,valid_loader,device,model,epochs,lr,accum_step,logger,log_per_step=None,early_stop=None):\n",
    "    device = device\n",
    "    logger.info(f'train on {device}')\n",
    "#     model = model.to(device)\n",
    "    \n",
    "    loss = nn.BCELoss()\n",
    "    opt = Adafactor(model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = train_per_epoch(train_loader,device,model,loss,opt,accum_step)\n",
    "        logger.info(f'epoch:{epoch},loss:{train_loss:.5f}')\n",
    "        \n",
    "        model.eval()\n",
    "        warnings.filterwarnings('ignore')\n",
    "        valid_acc,valid_precision,valid_recall,valid_f1 = evaluate_per_epoch(valid_loader,device,model,loss,epoch)\n",
    "        logger.info(f'epoch:{epoch},valid_acc:{valid_acc:.5f},valid_precision:{valid_precision:.5f},valid_recall:{valid_recall:.5f},valid_f1:{valid_f1:.5f}')\n",
    "        \n",
    "        if early_stop is not None:\n",
    "            stop = early_stop(valid_acc,model)\n",
    "            if stop:\n",
    "                logger.info('Early stopping')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57927f77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-21T08:18:29.608818Z",
     "start_time": "2021-12-21T08:18:07.933320Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-21 16:18:07,982 - INFO - train on cuda:0\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:06<00:00,  1.27it/s]\n",
      "2021-12-21 16:18:14,314 - INFO - epoch:0,loss:24.12807\n",
      "100%|█████████████████████████████████████████████| 8/8 [00:07<00:00,  1.07it/s]\n",
      "2021-12-21 16:18:21,786 - INFO - epoch:0,valid_acc:0.00000,valid_precision:0.00000,valid_recall:0.00000,valid_f1:0.00000\n"
     ]
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(model_savepath,patience)\n",
    "torch.cuda.empty_cache()\n",
    "if os.path.exists(log_path):\n",
    "    os.remove(log_path)\n",
    "if os.path.exists(evaluate_path):\n",
    "    os.remove(evaluate_path)\n",
    "logger = get_logger(log_path)\n",
    "train(train_loader,valid_loader,device,net,epochs,lr,accum_step,logger,early_stop=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99c05ff6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T02:48:41.739347Z",
     "start_time": "2021-12-23T02:48:25.601999Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 22/22 [00:15<00:00,  1.40it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = JecT5Dataset(test_data,tokenizer)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "net.load_state_dict(torch.load(model_savepath))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b7711b09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T03:13:18.909800Z",
     "start_time": "2021-12-23T03:13:18.903312Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(test_loader,device,model):\n",
    "    predicts = []\n",
    "    all_ids = []\n",
    "#     model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            id_ = batch['id']\n",
    "            ids = []\n",
    "            for i in range(0,len(id_),4):\n",
    "                ids.append(id_[i])\n",
    "            inputs = {key:value.to(device) for key,value in batch.items() if key!='answer' and key!='id' and key!='labels'}\n",
    "            out = model.generate(inputs)\n",
    "            for i in out:\n",
    "                a = tokenizer.decode(i, skip_special_tokens=True)\n",
    "                predict = process_t5_answer(a)\n",
    "                predicts.append(predict)\n",
    "            all_ids.extend(ids)\n",
    "        final_out = torch.tensor(predicts,dtype=torch.long).reshape(-1,4).tolist()\n",
    "    return final_out,all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fd2a4e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T03:27:44.850192Z",
     "start_time": "2021-12-23T03:13:19.590622Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1058/1058 [14:25<00:00,  1.22it/s]\n"
     ]
    }
   ],
   "source": [
    "all_res,all_ids = test(test_loader,device,net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aedc5c96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T03:27:48.922934Z",
     "start_time": "2021-12-23T03:27:48.913051Z"
    }
   },
   "outputs": [],
   "source": [
    "# all_res = all_res.tolist()\n",
    "alpha_ans = [process_answer(i) for i in all_res]\n",
    "alpha_ans = [op if len(op)>0 else ['C'] for op in alpha_ans]\n",
    "myres = dict(zip(all_ids,alpha_ans))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e2574af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-23T03:27:50.758261Z",
     "start_time": "2021-12-23T03:27:50.736644Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(predict_savepath,'w') as f:\n",
    "    json.dump(myres,f,ensure_ascii=False,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d834cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aad5d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
