{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29b57150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T12:58:52.495749Z",
     "start_time": "2021-12-22T12:58:51.053502Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import warnings\n",
    "import json\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import configparser\n",
    "from tqdm import tqdm\n",
    "from train_tools import EarlyStopping,get_logger\n",
    "from sklearn.metrics import accuracy_score, f1_score,precision_score,recall_score\n",
    "from transformers import AutoTokenizer,BertTokenizer,BartModel,BartConfig,Adafactor\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from data_prepare import data_prepare,process_answer\n",
    "from dataset_and_model import JecDataset,JecBartModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea1500b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T12:58:52.504458Z",
     "start_time": "2021-12-22T12:58:52.497842Z"
    }
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"config.ini\", encoding=\"utf-8\")\n",
    "section_name = 'bart'\n",
    "\n",
    "batch_size = config.getint(section_name,'batch_size')\n",
    "epochs = config.getint(section_name,'epochs')\n",
    "device = torch.device('cuda:'+config.get(section_name,'gpu') if torch.cuda.is_available else 'cpu')\n",
    "lr = config.getfloat(section_name,'batch_size')\n",
    "accum_step = config.getint(section_name,'accum_step')\n",
    "patience = config.getint(section_name,'patience')\n",
    "model_name = config.get(section_name,'model_name')\n",
    "model_savepath = config.get(section_name,'model_savepath')\n",
    "predict_savepath = config.get(section_name,'predict_savepath')\n",
    "log_path = config.get(section_name,'log_path')\n",
    "evaluate_path = config.get(section_name,'evaluate_path')\n",
    "\n",
    "train_datapath = config.get('DEFAULT','train_datapath')\n",
    "valid_datapath = config.get('DEFAULT','valid_datapath')\n",
    "test_datapath = config.get('DEFAULT','test_datapath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18789222",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T12:58:52.861359Z",
     "start_time": "2021-12-22T12:58:52.506092Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data,valid_data,test_data = data_prepare(train_datapath,test_datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8713379",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T12:58:52.875210Z",
     "start_time": "2021-12-22T12:58:52.862931Z"
    }
   },
   "outputs": [],
   "source": [
    "random.shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2c31eab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T12:58:52.990340Z",
     "start_time": "2021-12-22T12:58:52.877596Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BartTokenizer'. \n",
      "The class this function is called from is 'BertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0792185",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T12:58:56.955003Z",
     "start_time": "2021-12-22T12:58:52.991669Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  6.09it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:03<00:00,  1.07it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data = JecDataset(train_data[:40],tokenizer)\n",
    "valid_data = JecDataset(valid_data,tokenizer)\n",
    "train_loader = DataLoader(dataset=train_data,batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8456466",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T12:59:00.993118Z",
     "start_time": "2021-12-22T12:58:56.956356Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at transformerModels/chinese_bart and are newly initialized: ['classification_head.out_proj.weight', 'classification_head.out_proj.bias', 'classification_head.dense.weight', 'classification_head.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "net = JecBartModel(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a7075a34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T13:13:14.196578Z",
     "start_time": "2021-12-22T13:13:10.615477Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1])\n",
      "tensor([0, 0])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader:\n",
    "    inputs = {key:value for key,value in batch.items() if key!='answer' and key!='id'}\n",
    "    target = batch['answer']\n",
    "\n",
    "    l = net.generate(inputs)\n",
    "    print(target)\n",
    "    _,idx = torch.max(l,dim=1)\n",
    "\n",
    "    print(idx)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d4dc6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T06:42:59.712167Z",
     "start_time": "2021-12-22T06:42:59.712151Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_metric(target,pred):\n",
    "    acc = accuracy_score(target,pred)\n",
    "    f1 = f1_score(target,pred,average='macro')\n",
    "    precision = precision_score(target,pred,average='macro')\n",
    "    recall = recall_score(target,pred,average='macro')\n",
    "    return acc,f1,precision,recall\n",
    "\n",
    "def train_per_epoch(train_loader,device,model,loss,opt,accum_step,log_per_step=None):\n",
    "    l_sum = 0\n",
    "    for i,batch in enumerate(tqdm(train_loader)):\n",
    "        target = batch['answer'].to(device)\n",
    "        inputs = {key:value.to(device) for key,value in batch.items() if key!='answer' and key!='id'}\n",
    "        l = model(inputs,target)\n",
    "        l_sum += l.item()\n",
    "        l = l/accum_step\n",
    "        l.backward()\n",
    "        if (i+1)%accum_step==0 or (i+1)==len(train_loader):\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "    return l_sum/len(train_loader)\n",
    "\n",
    "def evaluate_per_epoch(valid_loader,device,model,loss,epoch):\n",
    "    predicts = []\n",
    "    targets = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader):\n",
    "            target = batch['answer']\n",
    "            inputs = {key:value.to(device) for key,value in batch.items() if key!='answer' and key!='id'}\n",
    "            out = model.generate(inputs)\n",
    "            targets.append(target)\n",
    "            predicts.append(out.cpu())\n",
    "            \n",
    "        targets = torch.cat(targets,dim=0)\n",
    "        out = torch.cat(predicts,dim=0)\n",
    "        _,out = torch.max(out,dim=1)\n",
    "        final_out = out.reshape(-1,4)\n",
    "        targets = targets.reshape(-1,4)\n",
    "        valid_acc ,valid_f1 ,valid_precision ,valid_recall = get_metric(targets,final_out)\n",
    "    \n",
    "    with open(evaluate_path,'a') as f:\n",
    "        f.write('epoch:'+str(epoch)+'\\n')\n",
    "        for i in final_out[:100]:\n",
    "            f.write(str(i)+'\\n')\n",
    "    return valid_acc,valid_precision,valid_recall,valid_f1\n",
    "    \n",
    "def train(train_loader,valid_loader,device,model,epochs,lr,accum_step,logger,log_per_step=None,early_stop=None):\n",
    "    device = device\n",
    "    logger.info(f'train on {device}')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    loss = nn.BCELoss()\n",
    "    opt = Adafactor(model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = train_per_epoch(train_loader,device,model,loss,opt,accum_step)\n",
    "        logger.info(f'epoch:{epoch},loss:{train_loss:.5f}')\n",
    "        \n",
    "        model.eval()\n",
    "        warnings.filterwarnings('ignore')\n",
    "        valid_acc,valid_precision,valid_recall,valid_f1 = evaluate_per_epoch(valid_loader,device,model,loss,epoch)\n",
    "        logger.info(f'epoch:{epoch},valid_acc:{valid_acc:.5f},valid_precision:{valid_precision:.5f},valid_recall:{valid_recall:.5f},valid_f1:{valid_f1:.5f}')\n",
    "        \n",
    "        if early_stop is not None:\n",
    "            stop = early_stop(valid_acc,model)\n",
    "            if stop:\n",
    "                logger.info('Early stopping')\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57927f77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T06:42:59.713211Z",
     "start_time": "2021-12-22T06:42:59.713196Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(model_savepath,patience)\n",
    "torch.cuda.empty_cache()\n",
    "if os.path.exists(log_path):\n",
    "    os.remove(log_path)\n",
    "if os.path.exists(evaluate_path):\n",
    "    os.remove(evaluate_path)\n",
    "logger = get_logger(log_path)\n",
    "train(train_loader,valid_loader,device,net,epochs,lr,accum_step,logger,early_stop=early_stopping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c05ff6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T06:42:59.713913Z",
     "start_time": "2021-12-22T06:42:59.713898Z"
    }
   },
   "outputs": [],
   "source": [
    "test_data = JecDataset(test_data,tokenizer)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
    "net.load_state_dict(torch.load(model_savepath))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7711b09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T06:42:59.715078Z",
     "start_time": "2021-12-22T06:42:59.715063Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(test_loader,device,model):\n",
    "    predicts = []\n",
    "    all_ids = []\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            ids = batch['id']\n",
    "            inputs = {key:value.to(device) for key,value in batch.items() if key!='answer' and key!='id'}\n",
    "            _,out = model(inputs)\n",
    "            predicts.append(out.cpu())\n",
    "            all_ids.extend(ids)\n",
    "            \n",
    "        out = torch.cat(predicts,dim=0)\n",
    "        _,out = torch.max(out,dim=1)\n",
    "        final_out = out.reshape(-1,4)\n",
    "    return final_out,all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd2a4e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T06:42:59.715785Z",
     "start_time": "2021-12-22T06:42:59.715771Z"
    }
   },
   "outputs": [],
   "source": [
    "all_res,all_ids = test(test_loader,device,net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedc5c96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T06:42:59.716859Z",
     "start_time": "2021-12-22T06:42:59.716842Z"
    }
   },
   "outputs": [],
   "source": [
    "all_res = all_res.tolist()\n",
    "alpha_ans = [process_answer(i) for i in all_res]\n",
    "alpha_ans = [op if len(op)>0 else ['C'] for op in alpha_ans]\n",
    "myres = dict(zip(all_ids,alpha_ans))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2574af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-22T06:42:59.717824Z",
     "start_time": "2021-12-22T06:42:59.717810Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(predict_savepath,'w') as f:\n",
    "    json.dump(myres,f,ensure_ascii=False,indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
